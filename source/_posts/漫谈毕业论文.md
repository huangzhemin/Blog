layout: post
comments: true
title: 漫谈毕业论文
date: 2015-08-02 19:44:17
categories: 生活
tags: [毕业, 随笔, 记录]
---
扯扯闲话，就从这研究生生活说起，学生生活固然是丰富多彩的，然而跟本科有所不同的是，我们已经成长为一个专业的人，或者终极目标是一名专业的人，专业的计算机人，慢慢的开始接触高级算法，机器学习，自然语言处理的一些相关模型，并用这些模型去解决一些实际问题，遇到问题不再会想着老师给你一套详细的解决办法，取而代之的是自己的思考，对学术的敬畏和对未知世界的探索，现实当中却又是举步维艰，虽然还没有参加9月份的正式校招，但在内推工作的时候就已经能感受到，只有爱你所做的，才能真正用心把它做好并得到大家的认可。这篇博文的名字叫做《漫谈毕业论文》，感觉有点扯远了，现在回归正题，扯一扯我这毕业论文的种种经过，写的比较随性，纯粹是个人闲扯。
<!--more-->
说起这毕业论文，学校可是很重视的，开题报告封面上的14年9月，赫然在目，到现在时间也差不多过去1年了，每每回忆过去的一年，都好像是什么也没做，但却能真真切切的感受到自己的成长，不单单是知识上的，我想更多的是在对事物认识上的，去年九月份用一个月时间吭出了一份开题报告，说是一个月，其实真正在思考的时间也不过几天，或者说是答辩前一天晚上，重要的工作总是在deadline的前一天做的，对于这一点，真心是无力吐槽，每次都在结果发生的时候想着之前自己为什么不多做些工作，那怕每天一点点，我想这样的困惑不仅仅是在自己身上，大家或多或少应该也是这样，因为这样的情况也同样发生在我周围人的身上。经历过一些之后不会说临时抱佛脚了，往往会给自己一个比较充裕的计划时间，问题又来了，总是觉得时间比较充裕，自己可以多看看基础，夯实一下知识点的附知点（这里姑且允许我引入附知点的概念，就是围绕这一个主要知识点展开的其他知识点），这样学着学着，其实感觉是不错的，可到了deadline才发现自己的工作并没有太大的进展，赶紧把重点拿出来学，就好像是吃饭的时候把好吃的留到最后一样，已经知道了这部分是好吃的，但就是在那墨迹不肯早点吃掉，等着不得不吃的时候，才发现凉了，没有那么好吃了，于是吃掉它就成了一个不得不完成的任务，而任务不同于享受，没有达到预期的任务会加速消耗人的精神力和愉悦感。

再次扯远，难道是想打字吐槽自己的行为方式了吗？OMG，开题结束的半年，论文工作算是又弃掉没有任何进展，到了15年3月份，写中期的时候，发现之前自己的工作对于写论文，并没有什么卵用，不过好在中期就是老师们想看看论文进展，督促一下，所以还是很顺利的就通过了，之后的日子，毕业论文算是正式提上日程，说是自己的毕业论文，倒不如说是在实现老师的想法，因为老师的想法能为这个实验室的建设多少做点什么，对于这种高逼格的事情，虽然并不是我想做的，但是我还是会去做，因为自诩格局还是不错的，并没有那么多称心如意的事情，才会让遵从内心这句话显得弥足珍贵。但是话又说回来，导师对我的影响还是很大的，不管是在对待学术的态度上，还是在平时的生活里，会潜移默化的影响我思考问题的方式，因为在我来，在很多方面，他是智慧的，这里就不一一举例了，毕业论文的题目叫《基于鲁棒语言模型的手写后处理方法》，名字念起来挺逗的，直白的说就是后处理方法的健壮性研究，目标很清晰，尝试着揪出识别错误的汉字，并通过语言模型纠正它，老师提出的想法是用skipgram模型来尝试，而这种skip根本就不是为了解决语料覆盖不充足，而是要跳过可能出错的字，然后算整句的ppl，即cost，其实就是看跳过哪个字符，产生的语句串的概率最大，ok，that all，听起来low爆了，半天时间搞定，我总不能就靠这个毕业吧，工作量在哪里，对于这种方法的准确率和实际应用效果，还没有做一定规模的测试，简单的测了一下，确实是有效果，但这样写论文肯定是不行的，而且揪出错误字之后，最大的问题就是要做错误字符纠正了，这样需要再次启用语言模型，来改正错误的字，想到的最简单的就是信息检索和ngram语言模型了，其实对于这种需要多个简单模型来组合使用的方法，从我内心上来讲是很不屑的，也就没有足够的动力去做这件事，好在博士大师兄的出现，为我找到了一条新的出路，之前已经有同学用CNN做过手写单字识别了，效果还是很不错的，有97.4%的准确率，师兄说可以用RNN加入上下文信息，这样的语言模型肯定是有信心做到更好的效果的，只是理论到实践，还需要做很多细节上的调整，但至少RNN是我从内心上能够接收的，所以很快的就把1700W条训练语料准备好了，下一步就是要实现RNN模型了，找工作的原因，先放了放，今天下午被老师召集开组会，没错，从来就没有周末这个概念，不过好在我经常把工作日当假期，^_^，所以也就无所谓了，用RNN直接跑整句的方法直接被老师给绕开了，我的理解就是这不是目前最需要解决的，老师的想法是想用神经语言模型去实现错误纠正，去对比之前用skip的方法，那么我现在要做的就是用Theano这个工具中的LSTM，先来跑出个神经语言模型，此处贴一个非常有参考价值的网站，github的个人主页[Awesome-rnn](http://jiwonkim.org/awesome-rnn/)，毕业论文就要在这个基础上着手了。

先写到这，在边做边扯的路上一路狂奔～